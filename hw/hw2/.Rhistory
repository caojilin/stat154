x = x[,1:50]
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
#c
x = x[,1:50]
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
#c
x = x[,1:50]
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
#c
x = x[,1:50]
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
# now we see that
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
# now we see that
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
# now we see that
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
# now we see that
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
# (a) Generate a simulated data set with 20 observations in each of
# three classes (i.e. 60 observations total), and 50 variables
set.seed(2)
x=matrix (rnorm (60*50,sd=3) , ncol =50)
x =as.data.frame(x)
for (i in 1:50) {
x[1:20, i] = x[1:20, i] + 3
}
for (i in 1:50) {
x[21:40, i] = x[21:40, i] - 3
}
dx = x
dx$color = "red"
dx[21:40,]$color = "blue"
dx[41:60,]$color = "green"
d = prcomp(x)
scores = d$x
plot(scores[,1], scores[,2], col=x$color )
# (a) Generate a simulated data set with 20 observations in each of
# three classes (i.e. 60 observations total), and 50 variables
set.seed(2)
x=matrix (rnorm (60*50,sd=3) , ncol =50)
x =as.data.frame(x)
for (i in 1:50) {
x[1:20, i] = x[1:20, i] + 3
}
for (i in 1:50) {
x[21:40, i] = x[21:40, i] - 3
}
dx = x
dx$color = "red"
dx[21:40,]$color = "blue"
dx[41:60,]$color = "green"
d = prcomp(x)
scores = d$x
plot(scores[,1], scores[,2], col=x$color )
# (a) Generate a simulated data set with 20 observations in each of
# three classes (i.e. 60 observations total), and 50 variables
set.seed(2)
x=matrix (rnorm (60*50,sd=3) , ncol =50)
x =as.data.frame(x)
for (i in 1:50) {
x[1:20, i] = x[1:20, i] + 3
}
for (i in 1:50) {
x[21:40, i] = x[21:40, i] - 3
}
dx = x
dx$color = "red"
dx[21:40,]$color = "blue"
dx[41:60,]$color = "green"
d = prcomp(x)
scores = d$x
plot(scores[,1], scores[,2], col=dx$color )
#c
x = x[,1:50]
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
# we see that kmean successfully classify the data
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
# now we see that k-mean cannot separate the data points in the third class.
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
# now we see that k-mean cannot separate the data points in the third class.
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
# now we see that k-mean cannot separate the data points in the third class.
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
# now we see that k-mean cannot separate the data points in the third class.
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
# now we see that k-mean cannot separate the data points in the third class.
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
# now we see that k-mean cannot separate the data points in the third class.
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#c
x = x[,1:50]
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
# we see that kmean successfully classify the data
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
scores[,1:2]
#f
km.out = kmeans(scores[,1:2], centers = 3, nstart = 20)
#f
km.out = kmeans(scores[,1:2], centers = 3, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
# plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
# plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
# plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
scores = prcomp(x)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
scores = prcomp(x)
# plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
dim(scores)
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
scores = prcomp(x)$x
# plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
# plot(scores[,1], scores[,2], col=(km.out$cluster+1) )d
dim(scores)
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
scores = prcomp(x)$x
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
scores = prcomp(x)$x
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
x
xx=matrix (rnorm (60*50,sd=3) , ncol =50)
xx=matrix (rnorm (20*50,sd=3) , ncol =50)
xx
dim(xx)
d = prcomp(xx)
dim(d$x)
xx=matrix (rnorm (50*20,sd=3) , ncol =20)
d = prcomp(xx)
dim(d$x)
plot(n, time_for_create, type="l",ylab="time", col="red",ylim=c(0,max(max(time_for_create), max(time_for_svd))))
n = c(2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048)
time_for_create = rep(0,length(n))
time_for_svd = rep(0,length(n))
for (i in 1:length(n)) {
start =Sys.time()
M = matrix(rnorm(n[i]*n[i]),n[i],n[i])
end = Sys.time()
time_for_create[i] = end - start
start =Sys.time()
svd(M)
end = Sys.time()
time_for_svd[i] = end - start
}
plot(n, time_for_create, type="l",ylab="time", col="red",ylim=c(0,max(max(time_for_create), max(time_for_svd))))
lines(n, time_for_svd, type="l", col="green")
legend('topright',c("time_for_create","time_for_svd") ,
lty=1, col=c('red', 'green'), bty='n', cex=.75)
plot(n, log(time_for_create), type="l",ylab="time", col="red",ylim=c(0,max(max(time_for_create), max(time_for_svd))))
lines(n, log(time_for_svd), type="l", col="green")
legend('topright',c("time_for_create","time_for_svd") ,
lty=1, col=c('red', 'green'), bty='n', cex=.75)
plot(n, log(time_for_create), type="l",ylab="time", col="red",ylim=c(0,max(max(log(time_for_create)), max(log(time_for_svd)))))
lines(n, log(time_for_svd), type="l", col="green")
legend('topright',c("time_for_create","time_for_svd") ,
lty=1, col=c('red', 'green'), bty='n', cex=.75)
plot(n, log(time_for_create), type="l",ylab="time", col="red")
lines(n, log(time_for_svd), type="l", col="green")
legend('topright',c("time_for_create","time_for_svd") ,
lty=1, col=c('red', 'green'), bty='n', cex=.75)
plot(n, log(time_for_create+1), type="l",ylab="time", col="red")
lines(n, log(time_for_svd+1), type="l", col="green")
legend('topright',c("time_for_create","time_for_svd") ,
lty=1, col=c('red', 'green'), bty='n', cex=.75)
runif(1, -2, 3)
runif(1, -2, 3)
?runif
# (a) Generate a simulated data set with 20 observations in each of
# three classes (i.e. 60 observations total), and 50 variables
set.seed(2)
x=matrix (rnorm (60*50,sd=3) , ncol =50)
x =as.data.frame(x)
for (i in 1:50) {
x[1:20, i] = x[1:20, i] + runif(1, -2, 3)
}
for (i in 1:50) {
x[21:40, i] = x[21:40, i] - runif(1, -2, 3)
}
dx = x
dx$color = "red"
dx[21:40,]$color = "blue"
dx[41:60,]$color = "green"
d = prcomp(x)
scores = d$x
plot(scores[,1], scores[,2], col=dx$color )
# (a) Generate a simulated data set with 20 observations in each of
# three classes (i.e. 60 observations total), and 50 variables
set.seed(2)
x=matrix (rnorm (60*50) , ncol =50)
x =as.data.frame(x)
for (i in 1:50) {
x[1:20, i] = x[1:20, i] + runif(1, -2, 3)
}
for (i in 1:50) {
x[21:40, i] = x[21:40, i] - runif(1, -2, 3)
}
dx = x
dx$color = "red"
dx[21:40,]$color = "blue"
dx[41:60,]$color = "green"
d = prcomp(x)
scores = d$x
plot(scores[,1], scores[,2], col=dx$color )
# (a) Generate a simulated data set with 20 observations in each of
# three classes (i.e. 60 observations total), and 50 variables
set.seed(2)
x=matrix (rnorm (60*50) , ncol =50)
x =as.data.frame(x)
for (i in 1:50) {
x[1:20, i] = x[1:20, i] + runif(1, -2, 3)
}
for (i in 1:50) {
x[21:40, i] = x[21:40, i] - runif(1, -2, 3)
}
dx = x
dx$color = "red"
dx[21:40,]$color = "blue"
dx[41:60,]$color = "green"
d = prcomp(x)
scores = d$x
plot(scores[,1], scores[,2], col=dx$color )
#c
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
# we see that kmean successfully classify the data
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
# now we see that in the graph k-mean cannot separate the middle data points ideally
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
# now we see that in the graph k-mean cannot separate the middle data points ideally
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
# now we see that in the graph k-mean cannot separate the middle data points ideally
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#from graph we can see that k-mean fails to classify data points.
#f
km.out = kmeans(scores[,1:2], centers = 3, nstart = 20)
km.out$cluster
table(km.out$cluster)
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#c
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(factor(km.out$cluster, levels = c(1,3,2), labels = c("K-means Cluster1", "K-means Cluster2", "K-means Cluster3")), factor(labs, levels = c(1,2,3), labels = c("True Cluster1", "True Cluster2", "True Cluster3")))  # be careful with the arbitrarily named cluster names from kmeans
#c
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
table(factor(km.out$cluster, levels = c(1,3,2), labels = c("K-means Cluster1", "K-means Cluster2", "K-means Cluster3")), factor(labs, levels = c(1,2,3), labels = c("True Cluster1", "True Cluster2", "True Cluster3")))  # be careful with the arbitrarily named cluster names from kmeans
table(factor(km.out$cluster, levels = c(1,3,2), labels = c("K-means Cluster1", "K-means Cluster2", "K-means Cluster3")), factor(labs, levels = c(1,2,3), labels = c("True Cluster1", "True Cluster2", "True Cluster3")))
#c
km.out = kmeans(x, centers =3, nstart = 20)
table(factor(km.out$cluster, levels = c(1,3,2), labels = c("K-means Cluster1", "K-means Cluster2", "K-means Cluster3")), factor(labs, levels = c(1,2,3), labels = c("True Cluster1", "True Cluster2", "True Cluster3")))
x
#c
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
# we see that kmean successfully classify the data
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#c
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep(1,20), rep(2,20), rep(3,20)))
# we see that kmean successfully classify the data
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep(1,20), rep(2,20), rep(3,20)))
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#d
km.out = kmeans(x, centers =2, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep(1,20), rep(2,20), rep(3,20)))
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep(1,20), rep(2,20), rep(3,20)))
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster)
scores = prcomp(x)$x
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep(1,20), rep(2,20), rep(3,20)))
scores = prcomp(x)$x
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep("11",20), rep("22",20), rep("23",20)))
scores = prcomp(x)$x
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#g
x = scale(x)
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep("TRUE1",20), rep("TRUE2",20), rep("TRUE3",20)))
scores = prcomp(x)$x
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#f
km.out = kmeans(scores[,1:2], centers = 3, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep("TRUE1",20), rep("TRUE2",20), rep("TRUE3",20)))
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep("TRUE1",20), rep("TRUE2",20), rep("TRUE3",20)))
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep("TRUE1",20), rep("TRUE2",20), rep("TRUE3",20)))
plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#e
km.out = kmeans(x, centers =4, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep("TRUE1",20), rep("TRUE2",20), rep("TRUE3",20)))
#plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
#c
km.out = kmeans(x, centers =3, nstart = 20)
km.out$cluster
table(km.out$cluster, c(rep(1,20), rep(2,20), rep(3,20)))
#plot(scores[,1], scores[,2], col=(km.out$cluster+1) )
# (a) Generate a simulated data set with 20 observations in each of
# three classes (i.e. 60 observations total), and 50 variables
set.seed(2)
x=matrix (rnorm (60*50) , ncol =50)
x =as.data.frame(x)
for (i in 1:50) {
x[1:20, i] = x[1:20, i] + runif(1, -2, 3)
}
for (i in 1:50) {
x[21:40, i] = x[21:40, i] - runif(1, -2, 3)
}
dx = x
dx$color = "red"
dx[21:40,]$color = "blue"
dx[41:60,]$color = "green"
# (b)
d = prcomp(x)
scores = d$x
plot(scores[,1], scores[,2], col=dx$color )
plot(n, log(time_for_create+1), type="l",ylab="time", col="red")
lines(n, log(time_for_svd+1), type="l", col="green")
legend('topright',c("time_for_create","time_for_svd") ,
lty=1, col=c('red', 'green'), bty='n', cex=.75)
